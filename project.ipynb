{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are analyzing the Speed Dating Experiment dataset from Kaggle\n",
    "\n",
    "[[[[[What is the data science problem you are trying to solve? Why does the problem matter? What could the results of your predictive model be used for? Why would we want to be able to predict the thing youâ€™re trying to predict? Then describe the dataset that you will use to tackle this problem.]]]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset involves a number of demographic and preference questions, which include asking participants to rate things like how important they think certain attributes are in a partner, how important they believe other people think they are, how they think they measure up, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import square, sqrt\n",
    "from pandas import DataFrame\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>undergra</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>income</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>expnum</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr5_1</th>\n",
       "      <th>sinc5_1</th>\n",
       "      <th>intel5_1</th>\n",
       "      <th>fun5_1</th>\n",
       "      <th>amb5_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>attr1_s</th>\n",
       "      <th>sinc1_s</th>\n",
       "      <th>intel1_s</th>\n",
       "      <th>fun1_s</th>\n",
       "      <th>amb1_s</th>\n",
       "      <th>shar1_s</th>\n",
       "      <th>attr3_s</th>\n",
       "      <th>sinc3_s</th>\n",
       "      <th>intel3_s</th>\n",
       "      <th>fun3_s</th>\n",
       "      <th>amb3_s</th>\n",
       "      <th>satis_2</th>\n",
       "      <th>length</th>\n",
       "      <th>numdat_2</th>\n",
       "      <th>attr7_2</th>\n",
       "      <th>sinc7_2</th>\n",
       "      <th>intel7_2</th>\n",
       "      <th>fun7_2</th>\n",
       "      <th>amb7_2</th>\n",
       "      <th>shar7_2</th>\n",
       "      <th>attr1_2</th>\n",
       "      <th>sinc1_2</th>\n",
       "      <th>intel1_2</th>\n",
       "      <th>fun1_2</th>\n",
       "      <th>amb1_2</th>\n",
       "      <th>shar1_2</th>\n",
       "      <th>attr4_2</th>\n",
       "      <th>sinc4_2</th>\n",
       "      <th>intel4_2</th>\n",
       "      <th>fun4_2</th>\n",
       "      <th>amb4_2</th>\n",
       "      <th>shar4_2</th>\n",
       "      <th>attr2_2</th>\n",
       "      <th>sinc2_2</th>\n",
       "      <th>intel2_2</th>\n",
       "      <th>fun2_2</th>\n",
       "      <th>amb2_2</th>\n",
       "      <th>shar2_2</th>\n",
       "      <th>attr3_2</th>\n",
       "      <th>sinc3_2</th>\n",
       "      <th>intel3_2</th>\n",
       "      <th>fun3_2</th>\n",
       "      <th>amb3_2</th>\n",
       "      <th>attr5_2</th>\n",
       "      <th>sinc5_2</th>\n",
       "      <th>intel5_2</th>\n",
       "      <th>fun5_2</th>\n",
       "      <th>amb5_2</th>\n",
       "      <th>you_call</th>\n",
       "      <th>them_cal</th>\n",
       "      <th>date_3</th>\n",
       "      <th>numdat_3</th>\n",
       "      <th>num_in_3</th>\n",
       "      <th>attr1_3</th>\n",
       "      <th>sinc1_3</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr7_3</th>\n",
       "      <th>sinc7_3</th>\n",
       "      <th>intel7_3</th>\n",
       "      <th>fun7_3</th>\n",
       "      <th>amb7_3</th>\n",
       "      <th>shar7_3</th>\n",
       "      <th>attr4_3</th>\n",
       "      <th>sinc4_3</th>\n",
       "      <th>intel4_3</th>\n",
       "      <th>fun4_3</th>\n",
       "      <th>amb4_3</th>\n",
       "      <th>shar4_3</th>\n",
       "      <th>attr2_3</th>\n",
       "      <th>sinc2_3</th>\n",
       "      <th>intel2_3</th>\n",
       "      <th>fun2_3</th>\n",
       "      <th>amb2_3</th>\n",
       "      <th>shar2_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>69,487.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "      <td>16.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>22.22</td>\n",
       "      <td>11.11</td>\n",
       "      <td>16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "   partner   pid  match  int_corr  samerace  age_o  race_o  pf_o_att  \\\n",
       "0        1  11.0      0      0.14         0   27.0     2.0      35.0   \n",
       "1        2  12.0      0      0.54         0   22.0     2.0      60.0   \n",
       "2        3  13.0      1      0.16         1   22.0     4.0      19.0   \n",
       "3        4  14.0      1      0.61         0   23.0     2.0      30.0   \n",
       "4        5  15.0      1      0.21         0   24.0     3.0      30.0   \n",
       "\n",
       "   pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  dec_o  attr_o  sinc_o  \\\n",
       "0      20.0      20.0      20.0       0.0       5.0      0     6.0     8.0   \n",
       "1       0.0       0.0      40.0       0.0       0.0      0     7.0     8.0   \n",
       "2      18.0      19.0      18.0      14.0      12.0      1    10.0    10.0   \n",
       "3       5.0      15.0      40.0       5.0       5.0      1     7.0     8.0   \n",
       "4      10.0      20.0      10.0      10.0      20.0      1     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age field  field_cd  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    2.0  21.0   Law       1.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    2.0  21.0   Law       1.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0   Law       1.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    2.0  21.0   Law       1.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    2.0  21.0   Law       1.0   \n",
       "\n",
       "  undergra mn_sat tuition  race  imprace  imprelig     from zipcode  \\\n",
       "0      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "1      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "2      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "3      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "4      NaN    NaN     NaN   4.0      2.0       4.0  Chicago  60,521   \n",
       "\n",
       "      income  goal  date  go_out  career  career_c  sports  tvsports  \\\n",
       "0  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "1  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "2  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "3  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "4  69,487.00   2.0   7.0     1.0  lawyer       NaN     9.0       2.0   \n",
       "\n",
       "   exercise  dining  museums  art  hiking  gaming  clubbing  reading   tv  \\\n",
       "0       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "1       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "2       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "3       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "4       8.0     9.0      1.0  1.0     5.0     1.0       5.0      6.0  9.0   \n",
       "\n",
       "   theater  movies  concerts  music  shopping  yoga  exphappy  expnum  \\\n",
       "0      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "1      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "2      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "3      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "4      1.0    10.0      10.0    9.0       8.0   1.0       3.0     2.0   \n",
       "\n",
       "   attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr4_1  sinc4_1  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "\n",
       "   intel4_1  fun4_1  amb4_1  shar4_1  attr2_1  sinc2_1  intel2_1  fun2_1  \\\n",
       "0       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "1       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "2       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "3       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "4       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "\n",
       "   amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  amb3_1  attr5_1  \\\n",
       "0     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "1     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "2     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "3     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "4     5.0      5.0      6.0      8.0     8.0       8.0     7.0      NaN   \n",
       "\n",
       "   sinc5_1  intel5_1  fun5_1  amb5_1  dec  attr  sinc  intel  fun  amb  shar  \\\n",
       "0      NaN       NaN     NaN     NaN    1   6.0   9.0    7.0  7.0  6.0   5.0   \n",
       "1      NaN       NaN     NaN     NaN    1   7.0   8.0    7.0  8.0  5.0   6.0   \n",
       "2      NaN       NaN     NaN     NaN    1   5.0   8.0    9.0  8.0  5.0   7.0   \n",
       "3      NaN       NaN     NaN     NaN    1   7.0   6.0    8.0  7.0  6.0   8.0   \n",
       "4      NaN       NaN     NaN     NaN    1   5.0   6.0    7.0  7.0  6.0   6.0   \n",
       "\n",
       "   like  prob  met  match_es  attr1_s  sinc1_s  intel1_s  fun1_s  amb1_s  \\\n",
       "0   7.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "1   7.0   5.0  1.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "2   7.0   NaN  1.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "3   7.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "4   6.0   6.0  2.0       4.0      NaN      NaN       NaN     NaN     NaN   \n",
       "\n",
       "   shar1_s  attr3_s  sinc3_s  intel3_s  fun3_s  amb3_s  satis_2  length  \\\n",
       "0      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "1      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "2      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "3      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "4      NaN      NaN      NaN       NaN     NaN     NaN      6.0     2.0   \n",
       "\n",
       "   numdat_2  attr7_2  sinc7_2  intel7_2  fun7_2  amb7_2  shar7_2  attr1_2  \\\n",
       "0       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "1       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "2       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "3       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "4       1.0      NaN      NaN       NaN     NaN     NaN      NaN    19.44   \n",
       "\n",
       "   sinc1_2  intel1_2  fun1_2  amb1_2  shar1_2  attr4_2  sinc4_2  intel4_2  \\\n",
       "0    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "1    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "2    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "3    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "4    16.67     13.89   22.22   11.11    16.67      NaN      NaN       NaN   \n",
       "\n",
       "   fun4_2  amb4_2  shar4_2  attr2_2  sinc2_2  intel2_2  fun2_2  amb2_2  \\\n",
       "0     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "1     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "2     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "3     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "4     NaN     NaN      NaN      NaN      NaN       NaN     NaN     NaN   \n",
       "\n",
       "   shar2_2  attr3_2  sinc3_2  intel3_2  fun3_2  amb3_2  attr5_2  sinc5_2  \\\n",
       "0      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "1      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "2      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "3      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "4      NaN      6.0      7.0       8.0     7.0     6.0      NaN      NaN   \n",
       "\n",
       "   intel5_2  fun5_2  amb5_2  you_call  them_cal  date_3  numdat_3  num_in_3  \\\n",
       "0       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "1       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "2       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "3       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "4       NaN     NaN     NaN       1.0       1.0     0.0       NaN       NaN   \n",
       "\n",
       "   attr1_3  sinc1_3  intel1_3  fun1_3  amb1_3  shar1_3  attr7_3  sinc7_3  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "\n",
       "   intel7_3  fun7_3  amb7_3  shar7_3  attr4_3  sinc4_3  intel4_3  fun4_3  \\\n",
       "0       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "1       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "2       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "3       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "4       NaN     NaN     NaN      NaN      NaN      NaN       NaN     NaN   \n",
       "\n",
       "   amb4_3  shar4_3  attr2_3  sinc2_3  intel2_3  fun2_3  amb2_3  shar2_3  \\\n",
       "0     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "1     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "2     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "3     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "4     NaN      NaN      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "\n",
       "   attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data and display all features for first 5 records\n",
    "df = pd.read_csv('./data/speed_dating_data.csv', engine='python')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features\n",
    "To start, we went through and examined all 195 features in the dataset, using domain knowledge and examining how many missing values were in each to determine which features to keep or remove.\n",
    "\n",
    "The questions asked of the participants are split into three time categories: Time1 being before/during the event (including demographic info, rating their partners, etc.), Time2 being the day after the event (only preference questions), and Time3 being 3-4 weeks after (including questions like whether they have actually gone on a date yet, etc.). \n",
    "\n",
    "By our domain knowledge, we decided to drop the features that come from Time2 and Time3, since they are all repeat questions from Time1, and the participants' attitudes _after_ they make their decisions likely won't help predict what went into their decision during the event. The Time2 and Time3 features likely provide good insight into how a person's feelings towards the process change, but likely have little impact on their decisions prior.\n",
    "\n",
    "The one feature from Time2 we decided to keep is satis_2, which indicates how satisfied they were with the people they met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 120)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[:, :'satis_2']\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, several questions were asked only to certain waves of participants - this means that many features are missing tons of values. For instance, the questions asked halfway through meeting all dates (rate the importance of certain attributes and your rating of your own attributes) were not asked of waves 1-5, 12-14, or 21 - more than half of participants.\n",
    "\n",
    "To examine, we can count the percentage of missing values for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positin1    0.220339\n",
       "shar_o      0.128432\n",
       "undergra    0.413464\n",
       "mn_sat      0.626044\n",
       "tuition     0.572332\n",
       "zipcode     0.126999\n",
       "income      0.489258\n",
       "expnum      0.785152\n",
       "attr4_1     0.225471\n",
       "sinc4_1     0.225471\n",
       "intel4_1    0.225471\n",
       "fun4_1      0.225471\n",
       "amb4_1      0.225471\n",
       "shar4_1     0.228097\n",
       "attr5_1     0.414419\n",
       "sinc5_1     0.414419\n",
       "intel5_1    0.414419\n",
       "fun5_1      0.414419\n",
       "amb5_1      0.414419\n",
       "shar        0.127357\n",
       "match_es    0.140010\n",
       "attr1_s     0.511101\n",
       "sinc1_s     0.511101\n",
       "intel1_s    0.511101\n",
       "fun1_s      0.511101\n",
       "amb1_s      0.511101\n",
       "shar1_s     0.511101\n",
       "attr3_s     0.522559\n",
       "sinc3_s     0.522559\n",
       "intel3_s    0.522559\n",
       "fun3_s      0.522559\n",
       "amb3_s      0.522559\n",
       "satis_2     0.109215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = data.isna().sum() / data.shape[0]\n",
    "nans[nans > 0.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the results, many features are missing upwards of 40% of their values. It doesn't make sense to try to try to drop rows or fill in these values since so many are missing, as this would greatly skew results. Also, most of them are very similar to earlier questions (eg. how you perceive yourself vs. how you think others perceive you), so dropping them likely won't have much impact. \n",
    "\n",
    "As an initial filtering, we remove those features with more than 40% of their values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dropped due to too many missing values:\n",
      "['undergra', 'mn_sat', 'tuition', 'income', 'expnum', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features dropped due to too many missing values:\")\n",
    "print(list((data.loc[:, (df.isna().sum() / data.shape[0]) >= 0.40]).columns ))\n",
    "data = data.loc[:, (df.isna().sum() / data.shape[0]) < 0.40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>satis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>60,521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "   partner   pid  match  int_corr  samerace  age_o  race_o  pf_o_att  \\\n",
       "0        1  11.0      0      0.14         0   27.0     2.0      35.0   \n",
       "1        2  12.0      0      0.54         0   22.0     2.0      60.0   \n",
       "2        3  13.0      1      0.16         1   22.0     4.0      19.0   \n",
       "3        4  14.0      1      0.61         0   23.0     2.0      30.0   \n",
       "4        5  15.0      1      0.21         0   24.0     3.0      30.0   \n",
       "\n",
       "   pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  dec_o  attr_o  sinc_o  \\\n",
       "0      20.0      20.0      20.0       0.0       5.0      0     6.0     8.0   \n",
       "1       0.0       0.0      40.0       0.0       0.0      0     7.0     8.0   \n",
       "2      18.0      19.0      18.0      14.0      12.0      1    10.0    10.0   \n",
       "3       5.0      15.0      40.0       5.0       5.0      1     7.0     8.0   \n",
       "4      10.0      20.0      10.0      10.0      20.0      1     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age field  field_cd  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    2.0  21.0   Law       1.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    2.0  21.0   Law       1.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0   Law       1.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    2.0  21.0   Law       1.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    2.0  21.0   Law       1.0   \n",
       "\n",
       "   race  imprace  imprelig     from zipcode  goal  date  go_out  career  \\\n",
       "0   4.0      2.0       4.0  Chicago  60,521   2.0   7.0     1.0  lawyer   \n",
       "1   4.0      2.0       4.0  Chicago  60,521   2.0   7.0     1.0  lawyer   \n",
       "2   4.0      2.0       4.0  Chicago  60,521   2.0   7.0     1.0  lawyer   \n",
       "3   4.0      2.0       4.0  Chicago  60,521   2.0   7.0     1.0  lawyer   \n",
       "4   4.0      2.0       4.0  Chicago  60,521   2.0   7.0     1.0  lawyer   \n",
       "\n",
       "   career_c  sports  tvsports  exercise  dining  museums  art  hiking  gaming  \\\n",
       "0       NaN     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0   \n",
       "1       NaN     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0   \n",
       "2       NaN     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0   \n",
       "3       NaN     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0   \n",
       "4       NaN     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0   \n",
       "\n",
       "   clubbing  reading   tv  theater  movies  concerts  music  shopping  yoga  \\\n",
       "0       5.0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0   \n",
       "1       5.0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0   \n",
       "2       5.0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0   \n",
       "3       5.0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0   \n",
       "4       5.0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0   \n",
       "\n",
       "   exphappy  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr4_1  \\\n",
       "0       3.0     15.0     20.0      20.0    15.0    15.0     15.0      NaN   \n",
       "1       3.0     15.0     20.0      20.0    15.0    15.0     15.0      NaN   \n",
       "2       3.0     15.0     20.0      20.0    15.0    15.0     15.0      NaN   \n",
       "3       3.0     15.0     20.0      20.0    15.0    15.0     15.0      NaN   \n",
       "4       3.0     15.0     20.0      20.0    15.0    15.0     15.0      NaN   \n",
       "\n",
       "   sinc4_1  intel4_1  fun4_1  amb4_1  shar4_1  attr2_1  sinc2_1  intel2_1  \\\n",
       "0      NaN       NaN     NaN     NaN      NaN     35.0     20.0      15.0   \n",
       "1      NaN       NaN     NaN     NaN      NaN     35.0     20.0      15.0   \n",
       "2      NaN       NaN     NaN     NaN      NaN     35.0     20.0      15.0   \n",
       "3      NaN       NaN     NaN     NaN      NaN     35.0     20.0      15.0   \n",
       "4      NaN       NaN     NaN     NaN      NaN     35.0     20.0      15.0   \n",
       "\n",
       "   fun2_1  amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  amb3_1  dec  \\\n",
       "0    20.0     5.0      5.0      6.0      8.0     8.0       8.0     7.0    1   \n",
       "1    20.0     5.0      5.0      6.0      8.0     8.0       8.0     7.0    1   \n",
       "2    20.0     5.0      5.0      6.0      8.0     8.0       8.0     7.0    1   \n",
       "3    20.0     5.0      5.0      6.0      8.0     8.0       8.0     7.0    1   \n",
       "4    20.0     5.0      5.0      6.0      8.0     8.0       8.0     7.0    1   \n",
       "\n",
       "   attr  sinc  intel  fun  amb  shar  like  prob  met  match_es  satis_2  \n",
       "0   6.0   9.0    7.0  7.0  6.0   5.0   7.0   6.0  2.0       4.0      6.0  \n",
       "1   7.0   8.0    7.0  8.0  5.0   6.0   7.0   5.0  1.0       4.0      6.0  \n",
       "2   5.0   8.0    9.0  8.0  5.0   7.0   7.0   NaN  1.0       4.0      6.0  \n",
       "3   7.0   6.0    8.0  7.0  6.0   8.0   7.0   6.0  2.0       4.0      6.0  \n",
       "4   5.0   6.0    7.0  7.0  6.0   6.0   6.0   6.0  2.0       4.0      6.0  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can drop certain features that won't have an impact on whether two people match. A list of dropped features and their justifications are below:\n",
    "\n",
    "- id, idg, partner: these ID numbers have no effect on the outcome\n",
    "- wave, round, position, positin1: these are factors about the process of the event (eg. station number) that will not affect whether two people match\n",
    "- dec (their decision), dec_o (decision of their partner): we're trying to determine whether these two people match, which could be directly found from dec and dec_o (if both are 1, match=1); using these would be cheating and remove all valuable insights.\n",
    "- zipcode: the numeric value of a zipcode is arbitrary and thus would mess up a machine learning model\n",
    "\n",
    "Note: we keep iid and pid for now so we can lookup people in order to do feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>condtn</th>\n",
       "      <th>order</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr4_1</th>\n",
       "      <th>sinc4_1</th>\n",
       "      <th>intel4_1</th>\n",
       "      <th>fun4_1</th>\n",
       "      <th>amb4_1</th>\n",
       "      <th>shar4_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>satis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  gender  condtn  order   pid  match  int_corr  samerace  age_o  race_o  \\\n",
       "0    1       0       1      4  11.0      0      0.14         0   27.0     2.0   \n",
       "1    1       0       1      3  12.0      0      0.54         0   22.0     2.0   \n",
       "2    1       0       1     10  13.0      1      0.16         1   22.0     4.0   \n",
       "3    1       0       1      5  14.0      1      0.61         0   23.0     2.0   \n",
       "4    1       0       1      7  15.0      1      0.21         0   24.0     3.0   \n",
       "\n",
       "   pf_o_att  pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  attr_o  sinc_o  \\\n",
       "0      35.0      20.0      20.0      20.0       0.0       5.0     6.0     8.0   \n",
       "1      60.0       0.0       0.0      40.0       0.0       0.0     7.0     8.0   \n",
       "2      19.0      18.0      19.0      18.0      14.0      12.0    10.0    10.0   \n",
       "3      30.0       5.0      15.0      40.0       5.0       5.0     7.0     8.0   \n",
       "4      30.0      10.0      20.0      10.0      10.0      20.0     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age field  field_cd  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    2.0  21.0   Law       1.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    2.0  21.0   Law       1.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0   Law       1.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    2.0  21.0   Law       1.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    2.0  21.0   Law       1.0   \n",
       "\n",
       "   race  imprace  imprelig     from  goal  date  go_out  career  career_c  \\\n",
       "0   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "1   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "2   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "3   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "4   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "\n",
       "   sports  tvsports  exercise  dining  museums  art  hiking  gaming  clubbing  \\\n",
       "0     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "1     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "2     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "3     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "4     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "\n",
       "   reading   tv  theater  movies  concerts  music  shopping  yoga  exphappy  \\\n",
       "0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "1      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "2      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "3      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "4      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "\n",
       "   attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr4_1  sinc4_1  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0      NaN      NaN   \n",
       "\n",
       "   intel4_1  fun4_1  amb4_1  shar4_1  attr2_1  sinc2_1  intel2_1  fun2_1  \\\n",
       "0       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "1       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "2       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "3       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "4       NaN     NaN     NaN      NaN     35.0     20.0      15.0    20.0   \n",
       "\n",
       "   amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  amb3_1  attr  sinc  \\\n",
       "0     5.0      5.0      6.0      8.0     8.0       8.0     7.0   6.0   9.0   \n",
       "1     5.0      5.0      6.0      8.0     8.0       8.0     7.0   7.0   8.0   \n",
       "2     5.0      5.0      6.0      8.0     8.0       8.0     7.0   5.0   8.0   \n",
       "3     5.0      5.0      6.0      8.0     8.0       8.0     7.0   7.0   6.0   \n",
       "4     5.0      5.0      6.0      8.0     8.0       8.0     7.0   5.0   6.0   \n",
       "\n",
       "   intel  fun  amb  shar  like  prob  met  match_es  satis_2  \n",
       "0    7.0  7.0  6.0   5.0   7.0   6.0  2.0       4.0      6.0  \n",
       "1    7.0  8.0  5.0   6.0   7.0   5.0  1.0       4.0      6.0  \n",
       "2    9.0  8.0  5.0   7.0   7.0   NaN  1.0       4.0      6.0  \n",
       "3    8.0  7.0  6.0   8.0   7.0   6.0  2.0       4.0      6.0  \n",
       "4    7.0  7.0  6.0   6.0   6.0   6.0  2.0       4.0      6.0  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list = ['id', 'idg', 'partner', 'wave', 'round', 'position', 'positin1', 'dec', 'dec_o', 'zipcode']\n",
    "data = data.drop(drop_list, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 89)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "drop zipcode, OHE for some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "After dropping many features either due to too many missing values or irrelevancy to the thing we're trying to predict (whether two people match), we are ready to begin exploring the features that remain.\n",
    "\n",
    "### Demographic features\n",
    "To start, we can analyze trends in the demographic features of participants.\n",
    "\n",
    "Since each person is listed multiple times (according to the number of people they met), we first need to get a dataframe where each participant is listed only once, to get a true representation of the demographic features present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants:  551\n"
     ]
    }
   ],
   "source": [
    "people = data.groupby('iid').first()\n",
    "print(\"Number of participants: \", people.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of females:  274\n",
      "Number of males:  277\n"
     ]
    }
   ],
   "source": [
    "genders = people.groupby('gender').size()\n",
    "print(\"Number of females: \", genders.iloc[0])\n",
    "print(\"Number of males: \", genders.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001BF2B2F6278>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "people.hist(column='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goal_labels = {\n",
    "    1: 'Seemed like a fun night out', \n",
    "    2: 'To meet new people', \n",
    "    3: 'To get a date', \n",
    "    4: 'Looking for a serious relationship', \n",
    "    5: 'To say I did it', \n",
    "    6: 'Other'\n",
    "}\n",
    "\n",
    "goals = people['goal'].value_counts().index.tolist()\n",
    "goals = [goal_labels[g] for g in goals]\n",
    "goal_counts = people['goal'].value_counts().to_list()\n",
    "\n",
    "plt.pie(goal_counts, labels=goals, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "race_labels = {\n",
    "    1: 'Black/African American', \n",
    "    2: 'European/Caucasian-American', \n",
    "    3: 'Latino/Hispanic American', \n",
    "    4: 'Asian/Pacific Islander/Asian-American', \n",
    "    5: 'Native American', \n",
    "    6: 'Other'\n",
    "}\n",
    "\n",
    "races = people['race'].value_counts().index.tolist()\n",
    "races = [race_labels[r] for r in races]\n",
    "race_counts = people['race'].value_counts().tolist()\n",
    "\n",
    "plt.pie(race_counts, labels=races, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bf3239c710>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "field_codes = {\n",
    "    1: 'Law',\n",
    "    2: 'Math',\n",
    "    3: 'Social Science, Psychologist',\n",
    "    4: 'Medical Science, Pharmaceuticals, and Bio Tech',\n",
    "    5: 'Engineering',\n",
    "    6: 'English/Creative Writing/Journalism',\n",
    "    7: 'History/Religion/Philosophy',\n",
    "    8: 'Business/Econ/Finance',\n",
    "    9: 'Education, Academia',\n",
    "    10: 'Biological Sciences/Chemistry/Physics',\n",
    "    11: 'Social Work',\n",
    "    12: 'Undergrad/undecided',\n",
    "    13: 'Political Science/International Affairs',\n",
    "    14: 'Film',\n",
    "    15: 'Fine Arts/Arts Administration',\n",
    "    16: 'Languages',\n",
    "    17: 'Architecture',\n",
    "    18: 'Other',\n",
    "}\n",
    "fields = people['field_cd'].copy().replace(field_codes)\n",
    "fields.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most participants tend to fall somewhere between the ages of 20-30, which makes sense as most of the participants are grad students at Columbia. There are also, however, participants upwards of 30 and some even up to 50.\n",
    "\n",
    "The gender split is pretty even, with 274 females and 277 males.\n",
    "\n",
    "The participants are primarily Caucasian and Asian/Pacific-Islander, with these two groups making up 55.8% and 25% of the participants, respectively. \n",
    "\n",
    "Business/Econ/Finance is far and away the most popular field of study; after a sharp dropoff, the next most popular fields are natural sciences, engineering, and law.\n",
    "\n",
    "Interestingly, most participants (76.6%) stated that their goal in participating in the event was either 'It seemed like a fun night out' or 'To meet new people.' Only 11.4% of participants stated their goal was either 'To get a date' or 'Looking for a serious relationship.' Therefore, it seems as though most participants are not extremely serious in their goals for participating; rather, most participated more for casual reasons - to have fun and meet new people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preference/rating features\n",
    "Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of shared demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bf25f54978>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importance of shared demographic features\n",
    "people.boxplot(column=['imprace', 'imprelig'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When asked how important it was that their partner be of the same race and religion on a scale of 1 to 10, the median answer for both was a 3. Additionally, the Q3 value is a 6. This indicates that most participants don't care very much that their partner share these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bf2fa5d080>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# their own hobbies\n",
    "plt.figure(figsize=(15, 5))\n",
    "people.loc[:, 'sports':'yoga'].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how participants rated their interest in these hobbies, we find that these people tend to be most interested in dining, reading, movies, and music.  \n",
    "\n",
    "There are outliers in many of these features, but this is to be expected - peoples' interests vary widely. However, there are also some points that are known to be errors - since the question was asked on a scale of 1 to 10, any values greater than 10 are noise. We replace any value >10 with 10, indicating the max level of interest in that hobby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['gaming'] > 10] = 10\n",
    "data[data['reading'] > 10] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you most look for in a partner of the opposite sex? What do you think the opposite sex looks for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding 'what do you think others look for?', attribute4_1 and attribute2_1 ask very similar questions to gauge how a participant thinks other people value these qualities. Since attribute4_1 was not asked to ~25% of the participants, we choose to drop those and keep attribute2_1, which asks \"what do you think the opposite sex looks for in a date?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop attr4_1 features\n",
    "data = data.drop(['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender\n",
    "gender_groups = people.groupby('gender')\n",
    "females = gender_groups.get_group(0)\n",
    "males = gender_groups.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(20, 20), sharey=True)\n",
    "\n",
    "# what females look for vs. what males think they look for\n",
    "ax1.title.set_text(\"What females look for\")\n",
    "ax2.title.set_text(\"What males think females look for\")\n",
    "females.loc[:, 'attr1_1':'shar1_1'].boxplot(ax=ax1)\n",
    "males.loc[:, 'attr2_1':'shar2_1'].boxplot(ax=ax2)\n",
    "\n",
    "# what males look for vs. what females think they look for\n",
    "ax3.title.set_text(\"What males look for\")\n",
    "ax4.title.set_text(\"What females think males look for\")\n",
    "males.loc[:, 'attr1_1':'shar1_1'].boxplot(ax=ax3)\n",
    "females.loc[:, 'attr2_1':'shar2_1'].boxplot(ax=ax4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male perception vs. how females actually value them\n",
      "Attractive: 4.91\n",
      "Sincere: -5.00\n",
      "Intelligent: -3.72\n",
      "Fun: 1.51\n",
      "Ambitious: 0.00\n",
      "Shared interests: -3.21\n"
     ]
    }
   ],
   "source": [
    "attributes = ['Attractive', 'Sincere', 'Intelligent', 'Fun', 'Ambitious', 'Shared interests']\n",
    "female_actual = females.loc[:, 'attr1_1':'shar1_1'].median().to_numpy()\n",
    "female_perceived = males.loc[:, 'attr2_1':'shar2_1'].median().to_numpy()\n",
    "female_diff = female_perceived - female_actual\n",
    "\n",
    "print(\"Male perception vs. how females actually value them\")\n",
    "for i in range(len(female_diff)):\n",
    "    print(attributes[i] + \": \" + \"%.2f\" % (female_diff[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female perception vs. how males actually value them\n",
      "Attractive: 7.00\n",
      "Sincere: -7.00\n",
      "Intelligent: -8.37\n",
      "Fun: 2.00\n",
      "Ambitious: 0.00\n",
      "Shared interests: 1.90\n"
     ]
    }
   ],
   "source": [
    "male_actual = males.loc[:, 'attr1_1':'shar1_1'].median().to_numpy()\n",
    "male_perceived = females.loc[:, 'attr2_1':'shar2_1'].median().to_numpy()\n",
    "male_diff = male_perceived - male_actual\n",
    "\n",
    "print(\"Female perception vs. how males actually value them\")\n",
    "for i in range(len(male_diff)):\n",
    "    print(attributes[i] + \": \" + \"%.2f\" % (male_diff[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot and outputs, we can see that males tend to value attractivness more than females, but that both sexes tend to overestimate how much the other sex values attractiveness. Both sexes also tend to underestimate sincerity and intelligence.\n",
    "\n",
    "Females tend to overestimate the importance of attractiveness and underestimate the importance of intelligence more so than males do towards females."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do you think you measure up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,7), sharey=True)\n",
    "\n",
    "plt.ylim(0,10)\n",
    "\n",
    "females.loc[:, 'attr3_1':'amb3_1'].boxplot(ax=ax1)\n",
    "ax1.title.set_text(\"How female participants rated themselves\")\n",
    "\n",
    "males.loc[:, 'attr3_1':'amb3_1'].boxplot(ax=ax2)\n",
    "ax2.title.set_text(\"How male participants rated themselves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When asked the question \"how do you think you measure up?\" on a scale of 1 to 10, males and females had quite similar responses. Most participants tend to rate themselves in the 7-9 range for most features. It's interesting to note that for both male and female participants, attractiveness had the lowest median rating out of all attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left to do: pf_o_attr, attr_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "After dropping certain features and exploring the ones that remain, there is still the issue of cleaning the data so that it can be used for feature engineering and our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>condtn</th>\n",
       "      <th>order</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>from</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>career</th>\n",
       "      <th>career_c</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>satis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Law</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  gender  condtn  order   pid  match  int_corr  samerace  age_o  race_o  \\\n",
       "0    1       0       1      4  11.0      0      0.14         0   27.0     2.0   \n",
       "1    1       0       1      3  12.0      0      0.54         0   22.0     2.0   \n",
       "2    1       0       1     10  13.0      1      0.16         1   22.0     4.0   \n",
       "3    1       0       1      5  14.0      1      0.61         0   23.0     2.0   \n",
       "4    1       0       1      7  15.0      1      0.21         0   24.0     3.0   \n",
       "\n",
       "   pf_o_att  pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  attr_o  sinc_o  \\\n",
       "0      35.0      20.0      20.0      20.0       0.0       5.0     6.0     8.0   \n",
       "1      60.0       0.0       0.0      40.0       0.0       0.0     7.0     8.0   \n",
       "2      19.0      18.0      19.0      18.0      14.0      12.0    10.0    10.0   \n",
       "3      30.0       5.0      15.0      40.0       5.0       5.0     7.0     8.0   \n",
       "4      30.0      10.0      20.0      10.0      10.0      20.0     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age field  field_cd  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    2.0  21.0   Law       1.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    2.0  21.0   Law       1.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0   Law       1.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    2.0  21.0   Law       1.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    2.0  21.0   Law       1.0   \n",
       "\n",
       "   race  imprace  imprelig     from  goal  date  go_out  career  career_c  \\\n",
       "0   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "1   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "2   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "3   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "4   4.0      2.0       4.0  Chicago   2.0   7.0     1.0  lawyer       NaN   \n",
       "\n",
       "   sports  tvsports  exercise  dining  museums  art  hiking  gaming  clubbing  \\\n",
       "0     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "1     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "2     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "3     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "4     9.0       2.0       8.0     9.0      1.0  1.0     5.0     1.0       5.0   \n",
       "\n",
       "   reading   tv  theater  movies  concerts  music  shopping  yoga  exphappy  \\\n",
       "0      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "1      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "2      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "3      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "4      6.0  9.0      1.0    10.0      10.0    9.0       8.0   1.0       3.0   \n",
       "\n",
       "   attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr2_1  sinc2_1  \\\n",
       "0     15.0     20.0      20.0    15.0    15.0     15.0     35.0     20.0   \n",
       "1     15.0     20.0      20.0    15.0    15.0     15.0     35.0     20.0   \n",
       "2     15.0     20.0      20.0    15.0    15.0     15.0     35.0     20.0   \n",
       "3     15.0     20.0      20.0    15.0    15.0     15.0     35.0     20.0   \n",
       "4     15.0     20.0      20.0    15.0    15.0     15.0     35.0     20.0   \n",
       "\n",
       "   intel2_1  fun2_1  amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  \\\n",
       "0      15.0    20.0     5.0      5.0      6.0      8.0     8.0       8.0   \n",
       "1      15.0    20.0     5.0      5.0      6.0      8.0     8.0       8.0   \n",
       "2      15.0    20.0     5.0      5.0      6.0      8.0     8.0       8.0   \n",
       "3      15.0    20.0     5.0      5.0      6.0      8.0     8.0       8.0   \n",
       "4      15.0    20.0     5.0      5.0      6.0      8.0     8.0       8.0   \n",
       "\n",
       "   amb3_1  attr  sinc  intel  fun  amb  shar  like  prob  met  match_es  \\\n",
       "0     7.0   6.0   9.0    7.0  7.0  6.0   5.0   7.0   6.0  2.0       4.0   \n",
       "1     7.0   7.0   8.0    7.0  8.0  5.0   6.0   7.0   5.0  1.0       4.0   \n",
       "2     7.0   5.0   8.0    9.0  8.0  5.0   7.0   7.0   NaN  1.0       4.0   \n",
       "3     7.0   7.0   6.0    8.0  7.0  6.0   8.0   7.0   6.0  2.0       4.0   \n",
       "4     7.0   5.0   6.0    7.0  7.0  6.0   6.0   6.0   6.0  2.0       4.0   \n",
       "\n",
       "   satis_2  \n",
       "0      6.0  \n",
       "1      6.0  \n",
       "2      6.0  \n",
       "3      6.0  \n",
       "4      6.0  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iid            0\n",
       "gender         0\n",
       "condtn         0\n",
       "order          0\n",
       "pid           10\n",
       "match          0\n",
       "int_corr     158\n",
       "samerace       0\n",
       "age_o        103\n",
       "race_o        73\n",
       "pf_o_att      89\n",
       "pf_o_sin      89\n",
       "pf_o_int      89\n",
       "pf_o_fun      98\n",
       "pf_o_amb     107\n",
       "pf_o_sha     128\n",
       "attr_o       210\n",
       "sinc_o       285\n",
       "intel_o      304\n",
       "fun_o        358\n",
       "amb_o        711\n",
       "shar_o      1061\n",
       "like_o       247\n",
       "prob_o       314\n",
       "met_o        377\n",
       "age           95\n",
       "field         63\n",
       "field_cd      82\n",
       "race          63\n",
       "imprace       79\n",
       "            ... \n",
       "yoga          79\n",
       "exphappy     101\n",
       "attr1_1       79\n",
       "sinc1_1       79\n",
       "intel1_1      79\n",
       "fun1_1        89\n",
       "amb1_1        99\n",
       "shar1_1      121\n",
       "attr2_1       79\n",
       "sinc2_1       79\n",
       "intel2_1      79\n",
       "fun2_1        79\n",
       "amb2_1        89\n",
       "shar2_1       89\n",
       "attr3_1      105\n",
       "sinc3_1      105\n",
       "fun3_1       105\n",
       "intel3_1     105\n",
       "amb3_1       105\n",
       "attr         201\n",
       "sinc         276\n",
       "intel        295\n",
       "fun          349\n",
       "amb          710\n",
       "shar        1066\n",
       "like         238\n",
       "prob         307\n",
       "met          372\n",
       "match_es    1105\n",
       "satis_2      915\n",
       "Length: 83, dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain binary features (condtn, met, and met_o), we transform the values from the scale provided (1 for yes, 2 for no) to a 0/1 scale (1 for yes, 0 for no). Then, we impute met and met_o (whether these two people have met before) with 0 - assuming that they haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change condtn, met, and met_o from 1(yes)/2(no) to 0(no)/1(yes)\n",
    "data.loc[data['condtn'] == 2, 'condtn'] = 0\n",
    "data.loc[data['met'] == 2, 'met'] = 0\n",
    "data.loc[data['met_o'] == 2, 'met_o'] = 0\n",
    "\n",
    "# impute met and met_o with 0 (haven't met)\n",
    "data['met'].fillna(0, inplace=True)\n",
    "data['met_o'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For correlation of interests, we impute with the mean.\n",
    "\n",
    "For races and samerace, we use the mode, since the values are coded (eg. 1: black, 2: white), so using an average or median doesn't make sense since they don't represent actual numerical values.\n",
    "\n",
    "For ages, we use the median age - almost all participants are grad students in the 20-30 range, so we choose the median rather than the mean to avoid it being skewed by some older participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# impute int_corr with the mean\n",
    "data[data['int_corr'] > 1] = 1\n",
    "data['int_corr'].fillna(data['int_corr'].mean(), inplace=True)\n",
    "\n",
    "# impute samerace with the mode\n",
    "data['samerace'].fillna(data['samerace'].mode()[0], inplace=True)\n",
    "\n",
    "# impute ages with median age\n",
    "med_age = people['age'].median()\n",
    "data['age_o'].fillna(med_age, inplace=True)\n",
    "data['age'].fillna(med_age, inplace=True)\n",
    "\n",
    "# impute races with mode\n",
    "mode_race = people['race'].mode()[0]\n",
    "data['race_o'].fillna(mode_race, inplace=True)\n",
    "data['race'].fillna(mode_race, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the features that have participants rate their preferences and interests, we use the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the mean for all of the preference/rating features\n",
    "data.loc[:, 'pf_o_att':'prob_o'] = data.loc[:, 'pf_o_att':'prob_o'].fillna(people.loc[:, 'pf_o_att':'prob_o'].mean())\n",
    "data.loc[:, 'imprace':'imprelig'] = data.loc[:, 'imprace':'imprelig'].fillna(people.loc[:, 'imprace':'imprelig'].mean())\n",
    "data.loc[:, 'sports':'prob'] = data.loc[:, 'sports':'prob'].fillna(people.loc[:, 'sports':'prob'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the 'from', 'career', and 'field' features, since these are all user-entry text answers, and thus the values could be anything - there is no way to one-hot encode them. We also drop career, since it is essentially the same as the field of study feature. We impute the most common field of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'from', 'career', and 'field' features, since all user-entered there's no way to OHE\n",
    "data.drop(['from', 'career', 'field'], axis=1, inplace=True)\n",
    "\n",
    "# drop career_c in favor of field of study\n",
    "data.drop('career_c', axis=1, inplace=True)\n",
    "\n",
    "# impute mode for field of study\n",
    "data['field_cd'].fillna(data['field_cd'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants were also asked to select an option that represents their goal, how often they go on dates, and how often they go out. Since, like race, these features are coded, using a mean or median doesn't make sense since they don't hold intrinsic numeric value - therefore, we use the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute goal, date, go_out with mode\n",
    "data['goal'].fillna(people['goal'].mode()[0], inplace=True)\n",
    "data['date'].fillna(people['date'].mode()[0], inplace=True)\n",
    "data['go_out'].fillna(people['go_out'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the expected number of matches and overall satisfaction with the event, we use the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean for expected number of matches and satisfaction\n",
    "data['match_es'].fillna(people['match_es'].mean(), inplace=True)\n",
    "data['satis_2'].fillna(people['satis_2'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check to see that all NaN values have been filled in (except for pid, which will be handled in feature engineering before eventually being dropped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid'], dtype='object')"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "After preprocessing our data, we are ready to start feature engineering - combining and modifying features to create better predictors of whether two people match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>condtn</th>\n",
       "      <th>order</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race_o</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>pf_o_fun</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>amb_o</th>\n",
       "      <th>shar_o</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>met_o</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>sports</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>museums</th>\n",
       "      <th>art</th>\n",
       "      <th>hiking</th>\n",
       "      <th>gaming</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>reading</th>\n",
       "      <th>tv</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>amb</th>\n",
       "      <th>shar</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "      <th>match_es</th>\n",
       "      <th>satis_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.156364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  gender  condtn  order   pid  match  int_corr  samerace  age_o  race_o  \\\n",
       "0    1       0       1      4  11.0      0      0.14         0   27.0     2.0   \n",
       "1    1       0       1      3  12.0      0      0.54         0   22.0     2.0   \n",
       "2    1       0       1     10  13.0      1      0.16         1   22.0     4.0   \n",
       "3    1       0       1      5  14.0      1      0.61         0   23.0     2.0   \n",
       "4    1       0       1      7  15.0      1      0.21         0   24.0     3.0   \n",
       "\n",
       "   pf_o_att  pf_o_sin  pf_o_int  pf_o_fun  pf_o_amb  pf_o_sha  attr_o  sinc_o  \\\n",
       "0      35.0      20.0      20.0      20.0       0.0       5.0     6.0     8.0   \n",
       "1      60.0       0.0       0.0      40.0       0.0       0.0     7.0     8.0   \n",
       "2      19.0      18.0      19.0      18.0      14.0      12.0    10.0    10.0   \n",
       "3      30.0       5.0      15.0      40.0       5.0       5.0     7.0     8.0   \n",
       "4      30.0      10.0      20.0      10.0      10.0      20.0     8.0     7.0   \n",
       "\n",
       "   intel_o  fun_o  amb_o  shar_o  like_o  prob_o  met_o   age  field_cd  race  \\\n",
       "0      8.0    8.0    8.0     6.0     7.0     4.0    0.0  21.0       1.0   4.0   \n",
       "1     10.0    7.0    7.0     5.0     8.0     4.0    0.0  21.0       1.0   4.0   \n",
       "2     10.0   10.0   10.0    10.0    10.0    10.0    1.0  21.0       1.0   4.0   \n",
       "3      9.0    8.0    9.0     8.0     7.0     7.0    0.0  21.0       1.0   4.0   \n",
       "4      9.0    6.0    9.0     7.0     8.0     6.0    0.0  21.0       1.0   4.0   \n",
       "\n",
       "   imprace  imprelig  goal  date  go_out  sports  tvsports  exercise  dining  \\\n",
       "0      2.0       4.0   2.0   7.0     1.0     9.0       2.0       8.0     9.0   \n",
       "1      2.0       4.0   2.0   7.0     1.0     9.0       2.0       8.0     9.0   \n",
       "2      2.0       4.0   2.0   7.0     1.0     9.0       2.0       8.0     9.0   \n",
       "3      2.0       4.0   2.0   7.0     1.0     9.0       2.0       8.0     9.0   \n",
       "4      2.0       4.0   2.0   7.0     1.0     9.0       2.0       8.0     9.0   \n",
       "\n",
       "   museums  art  hiking  gaming  clubbing  reading   tv  theater  movies  \\\n",
       "0      1.0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0   \n",
       "1      1.0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0   \n",
       "2      1.0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0   \n",
       "3      1.0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0   \n",
       "4      1.0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0   \n",
       "\n",
       "   concerts  music  shopping  yoga  exphappy  attr1_1  sinc1_1  intel1_1  \\\n",
       "0      10.0    9.0       8.0   1.0       3.0     15.0     20.0      20.0   \n",
       "1      10.0    9.0       8.0   1.0       3.0     15.0     20.0      20.0   \n",
       "2      10.0    9.0       8.0   1.0       3.0     15.0     20.0      20.0   \n",
       "3      10.0    9.0       8.0   1.0       3.0     15.0     20.0      20.0   \n",
       "4      10.0    9.0       8.0   1.0       3.0     15.0     20.0      20.0   \n",
       "\n",
       "   fun1_1  amb1_1  shar1_1  attr2_1  sinc2_1  intel2_1  fun2_1  amb2_1  \\\n",
       "0    15.0    15.0     15.0     35.0     20.0      15.0    20.0     5.0   \n",
       "1    15.0    15.0     15.0     35.0     20.0      15.0    20.0     5.0   \n",
       "2    15.0    15.0     15.0     35.0     20.0      15.0    20.0     5.0   \n",
       "3    15.0    15.0     15.0     35.0     20.0      15.0    20.0     5.0   \n",
       "4    15.0    15.0     15.0     35.0     20.0      15.0    20.0     5.0   \n",
       "\n",
       "   shar2_1  attr3_1  sinc3_1  fun3_1  intel3_1  amb3_1  attr  sinc  intel  \\\n",
       "0      5.0      6.0      8.0     8.0       8.0     7.0   6.0   9.0    7.0   \n",
       "1      5.0      6.0      8.0     8.0       8.0     7.0   7.0   8.0    7.0   \n",
       "2      5.0      6.0      8.0     8.0       8.0     7.0   5.0   8.0    9.0   \n",
       "3      5.0      6.0      8.0     8.0       8.0     7.0   7.0   6.0    8.0   \n",
       "4      5.0      6.0      8.0     8.0       8.0     7.0   5.0   6.0    7.0   \n",
       "\n",
       "   fun  amb  shar  like      prob  met  match_es  satis_2  \n",
       "0  7.0  6.0   5.0   7.0  6.000000  0.0       4.0      6.0  \n",
       "1  8.0  5.0   6.0   7.0  5.000000  1.0       4.0      6.0  \n",
       "2  8.0  5.0   7.0   7.0  5.156364  1.0       4.0      6.0  \n",
       "3  7.0  6.0   8.0   7.0  6.000000  0.0       4.0      6.0  \n",
       "4  7.0  6.0   6.0   6.0  6.000000  0.0       4.0      6.0  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the features that remain, there are many modifications we can make to create better predictors.\n",
    "\n",
    "First, we drop both race columns (race of this person & race of partner). It's not somebody's race alone that predicts whether they will match with someone else, but rather a factor of the two people's races together - namely, whether or not they are of the same race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['race', 'race_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we choose to drop both the age of this person and the age of their partner in favor of age difference. Similar to race, we want a feature that combines the features of these two people, rather than focusing on each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do age difference\n",
    "data['age_diff'] = (data['age'] - data['age_o']).abs()\n",
    "data.drop(['age', 'age_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine met and met_o into one feature, since it doesn't seem necessary to have two features telling whether they've met before or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine met and met_o\n",
    "data['met_both'] = data['met'] + data['met_o']\n",
    "data.drop(['met', 'met_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we drop the features 'date' and 'go_out', which ask participants how often they go on dates and how often they go out. These are dropped because they seem pretty in line with this person's goal and interests.\n",
    "\n",
    "We also drop this person's ratings for the various hobbies, since we already have a feature 'int_corr' that computes the correlation between this person's ratings and the other person's. One person's interests likely aren't a great predictor of a match - it's more dependent on how the two people's interests line up with each other.\n",
    "\n",
    "Finally, we drop all the attr2_1 features, which ask participants to rate what they think the opposite sex looks for in a date. While this is insightful information, one's guesses on how the other sex thinks likely has no impact on whether two specific people will match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop\n",
    "data.drop(['date', 'go_out'], axis=1, inplace=True)\n",
    "data.drop(data.loc[:, 'sports':'yoga'], axis=1, inplace=True)\n",
    "data.drop(data.loc[:, 'attr2_1':'shar2_1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we decided to create a confidence score for each person. They were all asked to rate themselves on the 6 attributes and also asked to state how many matches they think they'd get. These seem important in determining whether two people will match (if someone thinks they have a high rating and a large number of matches, each individual match is probably more likely); however, having 7 different features for it seems excessive. Therefore, we take the mean of these to create one 'confidence' score for each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confidence score\n",
    "data['conf'] = (data.loc[:, 'attr3_1':'amb3_1'].sum(axis=1) + data['match_es']) / 6\n",
    "data.drop('match_es', axis=1, inplace=True)\n",
    "data.drop(data.loc[:, 'attr3_1':'amb3_1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both this person and their partner were asked to rate how important 6 features were & rate their partner 1-10 on these same features. In both directions, we combine the importance with the rating to create a composite score. Ie., if person A thinks intelligence is super important and rates person B a 1/10, this should have a very low score; rating something of low importance means what they rate their partner matters less - the score should be close to the middle. \n",
    "\n",
    "Therefore, we use the method of `composite` = (`rating of partner out of 10` - 5) * `importance of that feature`\n",
    "\n",
    "This means that a low rating for an attribute will result in a negative score, but how heavily that score gets weighted depends on how much their partner values it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine pf_o_attr with att_o\n",
    "data['prating_att'] = data['pf_o_att'] * (data['attr_o'] - 5)\n",
    "data['prating_sinc'] = data['pf_o_sin'] * (data['sinc_o'] - 5)\n",
    "data['prating_intel'] = data['pf_o_int'] * (data['intel_o'] - 5)\n",
    "data['prating_fun'] = data['pf_o_fun'] * (data['fun_o'] - 5)\n",
    "data['prating_amb'] = data['pf_o_amb'] * (data['amb_o'] - 5)\n",
    "data['prating_shar'] = data['pf_o_sha'] * (data['shar_o'] - 5)\n",
    "\n",
    "# combine attr1 with attr\n",
    "data['rating_att'] = data['attr1_1'] * (data['attr'] - 5)\n",
    "data['rating_sinc'] = data['sinc1_1'] * (data['sinc'] - 5)\n",
    "data['rating_intel'] = data['intel1_1'] * (data['intel'] - 5)\n",
    "data['rating_fun'] = data['fun1_1'] * (data['fun'] - 5)\n",
    "data['rating_amb'] = data['amb1_1'] * (data['amb'] - 5)\n",
    "data['rating_shar'] = data['shar1_1'] * (data['shar'] - 5)\n",
    "\n",
    "data.drop(data.loc[:, 'attr1_1':'shar'], axis=1, inplace=True)\n",
    "data.drop(data.loc[:, 'pf_o_att':'shar_o'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also decided to combine the features `imprace` and `samerace`. This reflects both how important it is that they be of the same race with whether or not they actually are, rather than keeping these separate. \n",
    "\n",
    "To get this composite score, we store -1 * imprace if they are not of the same race, and just imprace if they are of the same race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine imprace and samerace\n",
    "data.loc[data['samerace'] == 0, 'samerace'] = -1\n",
    "data['imprace'] = data['samerace'] * data['imprace']\n",
    "data.drop('samerace', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a number of composite features were created by looking up the partner by their pid and taking some scores from their records. \n",
    "\n",
    "First, we combine the overall satisfaction levels for both partners. We do this in a similar way that F-measure is calculated from precision and recall, dividing the product of these values by their sum. This combines the two, but prioritizes the one that is lower (since a low satisfaction rate for either partner is a bad sign).\n",
    "\n",
    "Second, we check both people's fields of study and create a new feature for whether they have the same field of study or not. Similar to race, it's probably important that two people share such a feature, rather than looking at each one individually.\n",
    "\n",
    "Finally, we do the same thing for goal (what their goal with the event was), for a similar reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['satis_partner'] = 0\n",
    "data['same_field'] = 0\n",
    "data['same_goal'] = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    pid = row['pid']\n",
    "    partner_row = data.loc[data['iid'] == pid]\n",
    "    \n",
    "    if len(partner_row) < 1:\n",
    "        continue\n",
    "        \n",
    "    partner_satis = partner_row.iloc[0]['satis_2']\n",
    "    this_satis = row['satis_2']\n",
    "    row['satis_overall'] = (partner_satis * this_satis) / (partner_satis + this_satis)\n",
    "    \n",
    "    partner_field = partner_row.iloc[0]['field_cd']\n",
    "    row['same_field'] = 1 if partner_field == row['field_cd'] else 0\n",
    "        \n",
    "    partner_goal = partner_row.iloc[0]['goal']\n",
    "    row['same_goal'] = 1 if partner_goal == row['goal'] else 0\n",
    "    \n",
    "    data.iloc[index] = row\n",
    "    \n",
    "data.drop(['satis_2', 'field_cd', 'goal'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we drop the remaining id's from the dataframe, since their numeric values are arbitrary and won't help predict if two people match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['iid', 'pid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are left with 30 features with which to predict if two people mtch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8378, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>condtn</th>\n",
       "      <th>order</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>like_o</th>\n",
       "      <th>prob_o</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>met_both</th>\n",
       "      <th>conf</th>\n",
       "      <th>prating_att</th>\n",
       "      <th>prating_sinc</th>\n",
       "      <th>prating_intel</th>\n",
       "      <th>prating_fun</th>\n",
       "      <th>prating_amb</th>\n",
       "      <th>prating_shar</th>\n",
       "      <th>rating_att</th>\n",
       "      <th>rating_sinc</th>\n",
       "      <th>rating_intel</th>\n",
       "      <th>rating_fun</th>\n",
       "      <th>rating_amb</th>\n",
       "      <th>rating_shar</th>\n",
       "      <th>satis_partner</th>\n",
       "      <th>same_field</th>\n",
       "      <th>same_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.156364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>90.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  condtn  order  match  int_corr  like_o  prob_o  imprace  imprelig  \\\n",
       "0     0.0     1.0    4.0    0.0      0.14     7.0     4.0     -2.0       4.0   \n",
       "1     0.0     1.0    3.0    0.0      0.54     8.0     4.0     -2.0       4.0   \n",
       "2     0.0     1.0   10.0    1.0      0.16    10.0    10.0      2.0       4.0   \n",
       "3     0.0     1.0    5.0    1.0      0.61     7.0     7.0     -2.0       4.0   \n",
       "4     0.0     1.0    7.0    1.0      0.21     8.0     6.0     -2.0       4.0   \n",
       "\n",
       "   exphappy  like      prob  age_diff  met_both      conf  prating_att  \\\n",
       "0       3.0   7.0  6.000000       6.0       0.0  6.833333         35.0   \n",
       "1       3.0   7.0  5.000000       1.0       1.0  6.833333        120.0   \n",
       "2       3.0   7.0  5.156364       1.0       2.0  6.833333         95.0   \n",
       "3       3.0   7.0  6.000000       2.0       0.0  6.833333         60.0   \n",
       "4       3.0   6.0  6.000000       3.0       0.0  6.833333         90.0   \n",
       "\n",
       "   prating_sinc  prating_intel  prating_fun  prating_amb  prating_shar  \\\n",
       "0          60.0           60.0         60.0          0.0           5.0   \n",
       "1           0.0            0.0         80.0          0.0           0.0   \n",
       "2          90.0           95.0         90.0         70.0          60.0   \n",
       "3          15.0           60.0        120.0         20.0          15.0   \n",
       "4          20.0           80.0         10.0         40.0          40.0   \n",
       "\n",
       "   rating_att  rating_sinc  rating_intel  rating_fun  rating_amb  rating_shar  \\\n",
       "0        15.0         80.0          40.0        30.0        15.0          0.0   \n",
       "1        30.0         60.0          40.0        45.0         0.0         15.0   \n",
       "2         0.0         60.0          80.0        45.0         0.0         30.0   \n",
       "3        30.0         20.0          60.0        30.0        15.0         45.0   \n",
       "4         0.0         20.0          40.0        30.0        15.0         15.0   \n",
       "\n",
       "   satis_partner  same_field  same_goal  \n",
       "0            0.0         0.0        0.0  \n",
       "1            0.0         1.0        0.0  \n",
       "2            0.0         1.0        1.0  \n",
       "3            0.0         1.0        1.0  \n",
       "4            0.0         1.0        0.0  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "matches = data['match']\n",
    "features = data.drop(['match'], axis=1)\n",
    "\n",
    "std = StandardScaler()\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6284  603]\n",
      " [ 891  600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.89      6887\n",
      "         1.0       0.50      0.40      0.45      1491\n",
      "\n",
      "    accuracy                           0.82      8378\n",
      "   macro avg       0.69      0.66      0.67      8378\n",
      "weighted avg       0.81      0.82      0.81      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 29, 4)),\n",
    "    'dt_clf__max_depth': [10, 15, 20],\n",
    "    'dt_clf__min_samples_leaf': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('pca', pca),\n",
    "    ('dt_clf', dt_clf)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6431  456]\n",
      " [ 924  567]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90      6887\n",
      "         1.0       0.55      0.38      0.45      1491\n",
      "\n",
      "    accuracy                           0.84      8378\n",
      "   macro avg       0.71      0.66      0.68      8378\n",
      "weighted avg       0.82      0.84      0.82      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 29, 4)),\n",
    "    'knn_clf__n_neighbors': [3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('pca', pca),\n",
    "    ('knn_clf', knn_clf)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6608  279]\n",
      " [1094  397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.96      0.91      6887\n",
      "         1.0       0.59      0.27      0.37      1491\n",
      "\n",
      "    accuracy                           0.84      8378\n",
      "   macro avg       0.72      0.61      0.64      8378\n",
      "weighted avg       0.81      0.84      0.81      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 29, 4)),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('pca', pca),\n",
    "    ('nb_clf', nb_clf)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6459  428]\n",
      " [ 858  633]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      6887\n",
      "         1.0       0.60      0.42      0.50      1491\n",
      "\n",
      "    accuracy                           0.85      8378\n",
      "   macro avg       0.74      0.68      0.70      8378\n",
      "weighted avg       0.83      0.85      0.84      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 29, 4)),\n",
    "    'ada_clf__n_estimators': [50, 100, 150]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('pca', pca),\n",
    "    ('ada_clf', ada_clf)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6677  210]\n",
      " [ 995  496]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.97      0.92      6887\n",
      "         1.0       0.70      0.33      0.45      1491\n",
      "\n",
      "    accuracy                           0.86      8378\n",
      "   macro avg       0.79      0.65      0.68      8378\n",
      "weighted avg       0.84      0.86      0.83      8378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('pca', pca),\n",
    "    ('svc', svc),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 29, 4)),\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6422  465]\n",
      " [ 822  669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91      6887\n",
      "         1.0       0.59      0.45      0.51      1491\n",
      "\n",
      "    accuracy                           0.85      8378\n",
      "   macro avg       0.74      0.69      0.71      8378\n",
      "weighted avg       0.83      0.85      0.84      8378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# neural nets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std', std),\n",
    "    ('nn', nn),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'nn__hidden_layer_sizes': [(30,), (40,), (50,), (60,)],\n",
    "    'nn__activation': ['logistic', 'tanh', 'relu'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')\n",
    "preds = cross_val_predict(grid_search, features, matches, cv=5)\n",
    "\n",
    "confusion = confusion_matrix(matches, preds)\n",
    "report = classification_report(matches, preds)\n",
    "\n",
    "print(confusion)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
